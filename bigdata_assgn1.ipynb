{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyqyR8JWxJNiSpOY/AntVj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yadav-Raj-Ghimire/BigData/blob/main/bigdata_assgn1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "import sys\n",
        "import os\n",
        "python_path = sys.executable\n",
        "os.environ['PYSPARK_PYTHON'] = python_path\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Configure SparkSession. If a SparkContext already exists, getOrCreate() will reuse it.\n",
        "conf = SparkConf().setAppName(\"pyspark\").setMaster(\"local[*]\").set(\"spark.driver.host\",\"localhost\").set(\"spark.driver.allowMultipleContexts\",\"true\")\n",
        "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
        "sc = spark.sparkContext # Get the SparkContext from the existing SparkSession\n",
        "\n",
        "print(\"DONE==== START YOUR WORKðŸ‘‡ \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49MtEE4HsBtk",
        "outputId": "eeb7a5cb-07cc-4e1c-cc4b-2ca1fc722df8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE==== START YOUR WORKðŸ‘‡ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# PRINT VERSIONS OF BIG DATA TOOLS\n",
        "# ===============================\n",
        "\n",
        "import sys\n",
        "import pyspark\n",
        "import os\n",
        "\n",
        "print(\"ðŸ”¹ PYTHON VERSION\")\n",
        "print(sys.version)\n",
        "\n",
        "print(\"\\nðŸ”¹ PYSPARK VERSION\")\n",
        "print(pyspark.__version__)\n",
        "\n",
        "print(\"\\nðŸ”¹ SPARK VERSION\")\n",
        "print(spark.version)\n",
        "\n",
        "print(\"\\nðŸ”¹ JAVA VERSION\")\n",
        "!java -version\n",
        "\n",
        "print(\"\\nðŸ”¹ HADOOP VERSION (Bundled with Spark)\")\n",
        "print(os.path.basename(os.environ[\"SPARK_HOME\"]))\n",
        "\n",
        "print(\"\\nðŸ”¹ SPARK HOME\")\n",
        "print(os.environ[\"SPARK_HOME\"])\n",
        "\n",
        "print(\"\\nðŸ”¹ JAVA HOME\")\n",
        "print(os.environ[\"JAVA_HOME\"])\n",
        "\n",
        "print(\"\\nâœ… ALL BIG DATA TOOLS VERIFIED â€“ READY TO WORK ðŸš€\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OglnjaNXs-Q6",
        "outputId": "06c153e6-a9a1-422a-daa8-48f9d7721499"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ PYTHON VERSION\n",
            "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "\n",
            "ðŸ”¹ PYSPARK VERSION\n",
            "3.1.2\n",
            "\n",
            "ðŸ”¹ SPARK VERSION\n",
            "3.1.2\n",
            "\n",
            "ðŸ”¹ JAVA VERSION\n",
            "openjdk version \"1.8.0_472\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_472-8u472-ga-1~22.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.472-b08, mixed mode)\n",
            "\n",
            "ðŸ”¹ HADOOP VERSION (Bundled with Spark)\n",
            "spark-3.1.2-bin-hadoop2.7\n",
            "\n",
            "ðŸ”¹ SPARK HOME\n",
            "/content/spark-3.1.2-bin-hadoop2.7\n",
            "\n",
            "ðŸ”¹ JAVA HOME\n",
            "/usr/lib/jvm/java-8-openjdk-amd64\n",
            "\n",
            "âœ… ALL BIG DATA TOOLS VERIFIED â€“ READY TO WORK ðŸš€\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Configure Spark (already done in previous cell, reusing existing spark context)\n",
        "\n",
        "# Print a message to indicate the program has started\n",
        "print(\"STARTED=============\")\n",
        "\n",
        "\n",
        "# Create a list of strings containing the \"~\" separator\n",
        "listr = [\"A~B\", \"C~D\", \"E~F\"]\n",
        "\n",
        "# Print the original list\n",
        "print(\"\\n===== RAW LIST ======\")\n",
        "print(listr)\n",
        "\n",
        "# Convert the list into an RDD (Resilient Distributed Dataset)\n",
        "rddstr = sc.parallelize(listr)\n",
        "\n",
        "# Print the RDD contents\n",
        "print(\"\\n===== RDD LIST ======\")\n",
        "print(rddstr.collect())\n",
        "\n",
        "# Use flatMap() to split each string by the \"~\" separator\n",
        "# flatMap() applies the split operation to each element and flattens the results into a single RDD\n",
        "flatdata = rddstr.flatMap(lambda x: x.split(\"~\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlwhIfOpsaR1",
        "outputId": "45a0dc64-d468-4072-e994-0ad36df89f15"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTED=============\n",
            "\n",
            "===== RAW LIST ======\n",
            "['A~B', 'C~D', 'E~F']\n",
            "\n",
            "===== RDD LIST ======\n",
            "['A~B', 'C~D', 'E~F']\n"
          ]
        }
      ]
    }
  ]
}